{"subreddit": "programming", "gilded": 0, "downs": 0, "score": 9, "author": "jerf", "created_utc": "1193282288", "children": [{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 4, "author": "[deleted]", "created_utc": "1193300953", "children": [{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 5, "author": "api", "created_utc": "1193316166", "children": [{"subreddit": "programming", "gilded": 0, "downs": 0, "score": 2, "author": "[deleted]", "created_utc": "1193323604", "children": [{"subreddit": "programming", "gilded": 0, "downs": 0, "score": 1, "author": "api", "created_utc": "1193324535", "children": [{"controversiality": 0, "id": "c02b9gp", "subreddit": "programming", "author_flair_text": null, "ups": 1, "gilded": 0, "link_id": "t3_5z2az", "retrieved_on": 1427425403, "score": 1, "body": "  If you look at the intelligence humans are born with, it is certainly a huge kludge (quoting Marvin Minsky), that is optimized over millions of years. After birth, human child is subjected to 20+ years of different kinds of conditioning, and learning until it can work reasonably well in its environment. \n\nAny general learning mechanisms we have is finely balanced. Minuscule change in some  of the hundreds of parameters (like brain chemistry) and we go totally apeshit.   ", "author": "[deleted]", "created_utc": "1193325917", "downs": 0, "distinguished": null, "edited": true, "archived": true, "subreddit_id": "t5_2fwo", "score_hidden": false, "parent_id": "t1_c02b99q", "name": "t1_c02b9gp", "author_flair_css_class": null}], "subreddit_id": "t5_2fwo", "ups": 1, "score_hidden": false, "controversiality": 0, "archived": true, "link_id": "t3_5z2az", "retrieved_on": 1427425406, "id": "c02b99q", "author_flair_text": null, "distinguished": null, "edited": true, "name": "t1_c02b99q", "parent_id": "t1_c02b95p", "body": " I'd guess that human intelligence is somewhere between those two points: it's generally good but functions very well in problem domains that humans were commonly confronted with in their evolutionary history and poorly in domains that we weren't commonly confronted with. However, it's not so *overfit* so as to rule it out of those domains. It's just harder for us to, say, do statistics than it is for us to understand spatial relationships.\n\nAs computers get faster and faster, you're going to see a number of good generalist algorithms emerge (I think they'll probably be evolutionary, but that's my area so I'm biased) that can be marketed as \"shrink wrap\" solutions. They'll be good at a number of common problem domains, *acceptable* at others, and poor at a few. But even in the few that they're poor at, the computing power required to tackle them will still be cheaper than doing it manually with an army of human engineers.\n\nIn other words, AI is still coming. We just greatly underestimated the computing power required back when AI was hyped a lot-- by orders and orders of magnitude! To some extent the NFL theorem shows us why we underestimated the requirements so badly. NFL shows us that you will never be able to take trial-and-error out of the equation, while old classical AI was founded on the search for a magic *heuristic* that can *deterministically* solve everything in algorithmically acceptable time.\n", "author_flair_css_class": null}], "subreddit_id": "t5_2fwo", "ups": 2, "name": "t1_c02b95p", "controversiality": 0, "author_flair_text": null, "link_id": "t3_5z2az", "retrieved_on": 1427425407, "score_hidden": false, "body": "Exactly. Most algorithms have simple basic assumptions about data. like normal distribution, linearity, etc. Without learning bias it is impossible to generalize from the training set. \n\nEven within single learning algorithms there usually is room for trade off. You can usually adjust some parameters and choose between less general algorithm with good  results (in limited domain) and more general algorithm that is is is not so good performer in any particular problem domain.\n", "archived": true, "distinguished": null, "edited": false, "parent_id": "t1_c02b89o", "id": "c02b95p", "author_flair_css_class": null}], "subreddit": "programming", "score_hidden": false, "name": "t1_c02b89o", "controversiality": 0, "archived": true, "ups": 5, "link_id": "t3_5z2az", "retrieved_on": 1427425419, "id": "c02b89o", "author_flair_text": null, "distinguished": null, "edited": false, "parent_id": "t1_c02b7jk", "body": "But most fitness landscapes in the set of all possible fitness landscapes will be random, while most fitness landsacpes in nature are *not random*.\n\nThat's the kicker.\n", "author_flair_css_class": null}], "subreddit": "programming", "name": "t1_c02b7jk", "score_hidden": false, "controversiality": 0, "archived": true, "ups": 4, "link_id": "t3_5z2az", "retrieved_on": 1427425428, "id": "c02b7jk", "author_flair_text": null, "distinguished": null, "edited": false, "parent_id": "t1_c02b6ev", "body": "NFL don't prove AI and machine learning impossible. It basically means that *the average performance of any pair of algorithms across all possible problems is identical.* All possible problems is huge set. The space of all learning problems is mostly stuff that has no any patterns in the data. You can't beat rote learning on those cases.  \n\nWhat it means in reality, is that machine learning algorithms (and humans too) must have learning bias if they want to be better than just rote learning. In other words, when algorithms specialize, they can learn some class of problems much better than average while being less than average in other  problem domains. \n\n", "author_flair_css_class": null}, {"controversiality": 0, "downs": 0, "subreddit": "programming", "archived": true, "ups": 6, "gilded": 0, "link_id": "t3_5z2az", "retrieved_on": 1427425419, "score": 6, "body": "All NFL proves is that there are problems for which intelligence is useless or burdensome. An example would be a maliciously unhelpful task where all the clues lead to red herrings and the actual answer is senseless and random.\n\nThe existence of intelligence is essentially an embodied hypothesis, \"reality has patterns that make sense\".", "author": "JulianMorrison", "created_utc": "1193315998", "distinguished": null, "edited": false, "id": "c02b894", "author_flair_text": null, "subreddit_id": "t5_2fwo", "name": "t1_c02b894", "parent_id": "t1_c02b6ev", "score_hidden": false, "author_flair_css_class": null}], "subreddit_id": "t5_2fwo", "ups": 9, "score_hidden": false, "controversiality": 0, "archived": true, "link_id": "t3_5z2az", "retrieved_on": 1427425514, "id": "c02b6ev", "author_flair_text": null, "distinguished": null, "edited": true, "name": "t1_c02b6ev", "parent_id": "t3_5z2az", "body": " It may be worth pointing out that to the extent the NFL theorem proves AI and machine learning impossible, it equally proves _all_ manners of learning impossible. Including natural ones. Like any algorithms your brain may use.\n\nSo, either you are literally no more intelligent than any other random lump of matter in the universe, or the NFL theorem doesn't actually disprove the entire idea of intelligence.\n\nPersonally, I go for the second choice. Call me an egoist. YMMV. ", "author_flair_css_class": null}
{"controversiality": 0, "downs": 0, "subreddit_id": "t5_2fwo", "author_flair_text": null, "name": "t1_c02b7fv", "gilded": 0, "link_id": "t3_5z2az", "retrieved_on": 1427425429, "score": 2, "score_hidden": false, "id": "c02b7fv", "author": "jmmcd", "created_utc": "1193298993", "distinguished": null, "edited": false, "archived": true, "subreddit": "programming", "ups": 2, "parent_id": "t3_5z2az", "body": "I quite liked Rothlauf's *Representations* on this subject. Some of the 2nd edition is available as free downloads from his site.", "author_flair_css_class": null}
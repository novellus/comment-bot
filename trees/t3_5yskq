{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 16, "author": "lilspikey", "created_utc": "1192991062", "children": [{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 27, "author": "api", "created_utc": "1192993599", "children": [{"controversiality": 0, "downs": 0, "subreddit": "programming", "created_utc": "1192997090", "ups": 1, "gilded": 0, "link_id": "t3_5yskq", "retrieved_on": 1427425861, "score": 1, "body": "[deleted]", "author": "[deleted]", "archived": true, "distinguished": null, "edited": false, "id": "c02afn3", "author_flair_text": null, "subreddit_id": "t5_2fwo", "name": "t1_c02afn3", "parent_id": "t1_c02afd7", "score_hidden": false, "author_flair_css_class": null}, {"subreddit": "programming", "gilded": 0, "downs": 0, "score": 17, "author": "pchiusano", "created_utc": "1193010028", "children": [{"controversiality": 0, "retrieved_on": 1427425847, "subreddit_id": "t5_2fwo", "archived": true, "ups": 6, "gilded": 0, "link_id": "t3_5yskq", "downs": 0, "score": 6, "body": " True-- it did put an end to a lot of AI hooey of people claiming to have found magic shortcuts. That's a very clear way of putting it.\n\nBut I do think that you can now make two possible arguments about a learning algorithm: either it's very good in a given domain, or its a good generalist. But in either case you do have to a) back up what you say and b) you can't have both.\n\nThe latter is very interesting and important.\n\nEvolutionary algorithms tend to be good generalists, meaning that you're trading a lot of computing power for human effort.\n", "author": "api", "created_utc": "1193010164", "distinguished": null, "edited": true, "id": "c02agpf", "author_flair_text": null, "subreddit": "programming", "name": "t1_c02agpf", "parent_id": "t1_c02agot", "score_hidden": false, "author_flair_css_class": null}, {"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 6, "author": "[deleted]", "created_utc": "1193027079", "children": [{"subreddit": "programming", "gilded": 0, "downs": 0, "score": 2, "author": "api", "created_utc": "1193050164", "children": [{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 2, "author": "[deleted]", "created_utc": "1193068301", "children": [{"controversiality": 0, "downs": 0, "subreddit": "programming", "author_flair_text": null, "name": "t1_c02akp7", "gilded": 0, "link_id": "t3_5yskq", "retrieved_on": 1427425795, "score": 1, "score_hidden": false, "id": "c02akp7", "author": "api", "created_utc": "1193069335", "distinguished": null, "edited": true, "archived": true, "subreddit_id": "t5_2fwo", "ups": 1, "parent_id": "t1_c02akkf", "body": "Progress is still occurring in the areas of complexity theory and artificial life, but it's slowed by the fact that nobody is paying for this kind of research. I'm actually involved in an effort to commercialize an alife-based machine learning system, and we're going to have a release this December.\n\nAs I said elsewhere, evolutionary computation is a computationally-intensive general technique. As a result, we're going to see more and more of it as we get more and more computing power. It parallelizes quite easily, making it a potential \"killer app\" for massively multiprocessor/multicore machines. What else are we going to use our 64 cores for?\n\nOne of the reasons I think research in the alife area died down was processing power. In the middle 90s you didn't have enough, at least at a cost that researchers in this area could afford.\n", "author_flair_css_class": null}], "subreddit": "programming", "score_hidden": false, "ups": 2, "controversiality": 0, "archived": true, "link_id": "t3_5yskq", "retrieved_on": 1427425797, "id": "c02akkf", "author_flair_text": null, "distinguished": null, "edited": false, "name": "t1_c02akkf", "parent_id": "t1_c02aj6f", "body": "Unfortunately I'm out of touch with current research. My knowledge dates back to the mid '90s where great attention was spent to \"softcomputing\", complexity theory, artificial life etc. It was an optimistic era  in this domain. At that time I skimmed through a broad range of conference reports in a university library and programmed training algorithms for machines ( it was the way I taught myself programming ). I don't even know if progress has happened since then. \n\nI wouldn't be too angry when someone starts a blog or links to related articles on reddit. Since I'm getting downmodded by reddit bots right after posting a link I won't do it myself.", "author_flair_css_class": null}], "subreddit_id": "t5_2fwo", "name": "t1_c02aj6f", "score_hidden": false, "controversiality": 0, "author_flair_text": null, "ups": 2, "link_id": "t3_5yskq", "retrieved_on": 1427425815, "body": "Do you have any good links or paper references on the topic you discuss in your last paragraph? Brain hungry!\n", "archived": true, "distinguished": null, "edited": false, "parent_id": "t1_c02ai0o", "id": "c02aj6f", "author_flair_css_class": null}], "subreddit": "programming", "ups": 6, "name": "t1_c02ai0o", "controversiality": 0, "author_flair_text": null, "link_id": "t3_5yskq", "retrieved_on": 1427425830, "score_hidden": false, "body": "  *Post-NFL, people claiming to have come up with a \"better\" optimization technique now need to actually characterize the class of problems their technique is \"better\" for (at least, if they hope to be taken seriously!).*\n\nBut that's an obstacle for GAs, Simulated Annealing, NNs etc. The class of \"mildly structured problems\" can hardly be characterized geometrically. That's why those algorithms are usually applied to a number of sample problems that are considered as representative for optimization problems in the real world. \n\nOne of the most interesting challenges in conceptual research is finding ways to specify order that is somehow \"interesting\" or \"mildly structured\". From a good heuristic search algorithm we expect it to be responsive to structured domains. This leads somehow to a reversal of your authoritive suggestion: GAs and Co might be needed to give characterizations of those. So how do we measure the amount of structure in the solution space? By checking out whether Simulated Annealing performs better on average than pure random search. This is not a particular good measure but an upper bound.\n\n  ", "archived": true, "distinguished": null, "edited": true, "parent_id": "t1_c02agot", "id": "c02ai0o", "author_flair_css_class": null}], "subreddit_id": "t5_2fwo", "name": "t1_c02agot", "score_hidden": false, "controversiality": 0, "archived": true, "ups": 17, "link_id": "t3_5yskq", "retrieved_on": 1427425847, "id": "c02agot", "author_flair_text": null, "distinguished": null, "edited": false, "parent_id": "t1_c02afd7", "body": "&gt; ... which is a key little detail that greatly reduces the real-world applicability of NFL.\n\nThink of NFL as a *formal* statement of the importance of domain knowledge. If you know absolutely *nothing* about your problem domain, you can't do better than random search. Although this might seem obvious, before NFL, you had people coming up with optimization techniques, testing them on a few toy problems, and then claiming that they'd found a \"better\" technique. \n\nPost-NFL, people claiming to have come up with a \"better\" optimization technique now need to actually characterize the class of problems their technique is \"better\" for (at least, if they hope to be taken seriously!). So in that sense, NFL has been *extremely* important!\n\nI agree, however, that NFL has been used to make a lot of overblown claims (like Dembski) and is often misunderstood. But I still think it was an important result.", "author_flair_css_class": null}], "subreddit": "programming", "ups": 27, "name": "t1_c02afd7", "controversiality": 0, "author_flair_text": null, "link_id": "t3_5yskq", "retrieved_on": 1427425864, "score_hidden": false, "body": "... which is a key little detail that greatly reduces the real-world applicability of NFL.\n\nThe real world does not present the set of all possible optimization problems. There are also other problems: there have been shown to be \"free lunches\" in certain classes of coevolutionary games for example.\n\nNFL is actually a poorly understood theorem when it comes to its real world implications. It also seems to be about as frequently misused, over-hyped, and brandished about in support of woo-woo as poor Godel's incompleteness theorem.\n\nThe blog Good Math, Bad Math has a whole bunch of good posts related to the claims by creationists about NFL, such as this one:\n\nhttp://scienceblogs.com/goodmath/2006/06/dembski_and_no_free_lunch_with_2.php\n\nThe also relate to some of the overblown claims that people make about NFL prohibiting general purpose machine learning, etc.\n\nFrom the blog post:\n\n\"At heart, this is a fancy tautology. The key is that \"averaged over all fitness functions\" bit. If you average over all fitness functions, then every node has the same fitness. So, in other words, if you consider a search in which you can't tell the difference between different nodes, and a search in which you don't look at the difference between different nodes, then you'll get equivalently bad results.\"\n\nYeah, what he said.\n\nIf you want more pretty math symbols, try this:\n\nhttp://www.boundedtheoretics.com/CEC04.pdf\n", "archived": true, "distinguished": null, "edited": true, "parent_id": "t1_c02af5d", "id": "c02afd7", "author_flair_css_class": null}, {"controversiality": 0, "downs": 0, "subreddit_id": "t5_2fwo", "created_utc": "1193021339", "name": "t1_c02ahln", "gilded": 0, "link_id": "t3_5yskq", "retrieved_on": 1427425835, "score": 3, "score_hidden": false, "body": "To be pedantic, it's true across any set closed under permutation.", "author": "deong", "archived": true, "distinguished": null, "edited": false, "author_flair_text": null, "subreddit": "programming", "ups": 3, "parent_id": "t1_c02af5d", "id": "c02ahln", "author_flair_css_class": null}], "subreddit": "programming", "score_hidden": false, "ups": 16, "controversiality": 0, "archived": true, "link_id": "t3_5yskq", "retrieved_on": 1427425867, "id": "c02af5d", "author_flair_text": null, "distinguished": null, "edited": false, "name": "t1_c02af5d", "parent_id": "t3_5yskq", "body": "though of course that's across the set of _all_ optimization problems.", "author_flair_css_class": null}
{"controversiality": 0, "retrieved_on": 1427425852, "subreddit_id": "t5_2fwo", "archived": true, "name": "t1_c02age6", "gilded": 0, "link_id": "t3_5yskq", "downs": 0, "score": 4, "score_hidden": false, "body": "I don't like it. Rather convoluted explanation too..", "author": "IHaveAnIdea", "created_utc": "1193006297", "distinguished": null, "edited": false, "author_flair_text": null, "subreddit": "programming", "ups": 4, "parent_id": "t3_5yskq", "id": "c02age6", "author_flair_css_class": null}
{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 9, "author": "schwarzwald", "created_utc": "1193008003", "children": [{"controversiality": 0, "downs": 0, "subreddit_id": "t5_2fwo", "archived": true, "ups": 10, "gilded": 0, "link_id": "t3_5yskq", "retrieved_on": 1427425848, "score": 10, "id": "c02agno", "author": "api", "created_utc": "1193009744", "distinguished": null, "edited": true, "body": " \"the theorem puts an end to the search for the One Heuristic to Rule Them All\"\n\nIn a theoretical ivory tower sense, you're right. But like I said in another reply, the real world does not present to us the set of all possible fitness landscapes. It presents a set of sets of fitness landscapes with certain characteristics. So there is still a search for good learning algoritms that are both good in certain domains and that are good at reconfiguring themselves to be good generalists.\n\nNFL just proves that there isn't a magic shortcut that totally bypasses the need for a certain amount of brute force. When you're looking for optimums in a space, there will always be a need for good old fashioned trial and error at some stage in the process. Philosophically it is a cousin to Godel's theorem and the Church-Turing thesis in that it reinforces the same general idea: that there's no magic shortcut to instant perfection or perfect understanding of a system.\n\nEvolutionary algorithms are good generalists because they combine the ability to quickly climb hills (which are very common in *real world* fitness landscapes) with a certain amount of brute force staggering around and random search. Biological evolution adds the property of the \"evolution of evolvability,\" which means that evolution also conducts a meta-search or \"search for searches.\" Meta-search doesn't invalidate NFL in ivory-tower theory-land, but in the real world what you have is, like I said above, sets of sets of fitness landscapes that can be grouped by different common characteristics. Biological evolution is good at finding different search strategies that work in different domains.\n\nI hope that made sense. :P\n", "author_flair_text": null, "subreddit": "programming", "name": "t1_c02agno", "parent_id": "t1_c02agiq", "score_hidden": false, "author_flair_css_class": null}], "subreddit": "programming", "name": "t1_c02agiq", "score_hidden": false, "controversiality": 0, "archived": true, "ups": 9, "link_id": "t3_5yskq", "retrieved_on": 1427425849, "id": "c02agiq", "author_flair_text": null, "distinguished": null, "edited": false, "parent_id": "t3_5yskq", "body": "the theorem puts an end to the search for the One Heuristic to Rule Them All. but almost always you're approaching things from an extremely domain-specific perspective (you just want to route your shit in a reasonable amount of time or whatever).\n\nthe problem is that for these practical learning/optimization problems you sometimes can't do any better than what an elementary algorithm will give you (vanilla naive bayes or whatever) and it's not in general clear when this will occur.\n\ngenetic algorithms were/are pariahs for quite a while because it's hard to rigorously prove where they'll work. they were developed and popularized by engineers who don't give a shit about formal properties, they just knew that it worked for the things they were working on.", "author_flair_css_class": null}
{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 8, "author": "abhik", "created_utc": "1193009751", "children": [{"controversiality": 0, "downs": 0, "subreddit": "programming", "created_utc": "1193058458", "name": "t1_c02ajmj", "gilded": 0, "link_id": "t3_5yskq", "retrieved_on": 1427425809, "score": 1, "score_hidden": false, "id": "c02ajmj", "author": "api", "archived": true, "distinguished": null, "edited": false, "author_flair_text": null, "subreddit_id": "t5_2fwo", "ups": 1, "parent_id": "t1_c02agnq", "body": "Here's another interesting wrinkle:\n\nWhile it's true that a specialized algorithm constructed with domain knowledge will outperform a more general algorithm in a computational sense, in the real world you must take into account the total cost of producing and running the algorithm. Human time is far more expensive than computer time, meaning that in the real world a generalist algorithm might be far \"cheaper\" in a TCO sense than a specialized algorithm if you factor in the cost of developing the specialized algorithm manually.\n", "author_flair_css_class": null}], "subreddit": "programming", "score_hidden": false, "ups": 8, "controversiality": 0, "archived": true, "link_id": "t3_5yskq", "retrieved_on": 1427425848, "id": "c02agnq", "author_flair_text": null, "distinguished": null, "edited": false, "name": "t1_c02agnq", "parent_id": "t3_5yskq", "body": "I interpret the NFL as telling me that an algorithm with domain specific knowledge of my problem will outperform a more \"blind\" or general algorithm.  Of course, for some problems, I don't care to spend the time crafting a new algorithm if a generic one performs well enough. In other words, there's no silver bullet and my judgement still matters.", "author_flair_css_class": null}
{"controversiality": 0, "downs": 0, "subreddit": "programming", "archived": true, "name": "t1_c02ah3y", "gilded": 0, "link_id": "t3_5yskq", "retrieved_on": 1427425843, "score": 1, "id": "c02ah3y", "author": "drosser", "created_utc": "1193014906", "distinguished": null, "edited": true, "body": " I like the Random Sort algorithm even better. Go Grimjack! ", "author_flair_text": null, "subreddit_id": "t5_2fwo", "ups": 1, "parent_id": "t3_5yskq", "score_hidden": false, "author_flair_css_class": null}
{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 3, "author": "bobtheplanet", "created_utc": "1193061209", "children": [{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 9, "author": "api", "created_utc": "1193063606", "children": [{"subreddit_id": "t5_2fwo", "gilded": 0, "downs": 0, "score": 2, "author": "bobtheplanet", "created_utc": "1193065501", "children": [{"controversiality": 0, "downs": 0, "subreddit": "programming", "created_utc": "1193081158", "ups": 1, "gilded": 0, "link_id": "t3_5yskq", "retrieved_on": 1427425774, "score": 1, "score_hidden": false, "id": "c02amcl", "author": "api", "author_flair_text": null, "distinguished": null, "edited": false, "archived": true, "subreddit_id": "t5_2fwo", "name": "t1_c02amcl", "parent_id": "t1_c02ak8x", "body": "Actually, there might be real things that really are hard for evolution to access.\n\nFor example, why are there no wheeled gazelle?\n", "author_flair_css_class": null}], "subreddit": "programming", "ups": 2, "name": "t1_c02ak8x", "controversiality": 0, "author_flair_text": null, "link_id": "t3_5yskq", "retrieved_on": 1427425802, "score_hidden": false, "body": "Quite rightly so, otherwise we would be up against Sharks with \"frikkin' laser-beams\"", "archived": true, "distinguished": null, "edited": false, "parent_id": "t1_c02ak1t", "id": "c02ak8x", "author_flair_css_class": null}], "subreddit": "programming", "ups": 9, "name": "t1_c02ak1t", "controversiality": 0, "archived": true, "link_id": "t3_5yskq", "retrieved_on": 1427425804, "score_hidden": false, "id": "c02ak1t", "author_flair_text": null, "distinguished": null, "edited": true, "parent_id": "t1_c02aju6", "body": "That's very close to the right idea.\n\nIn evolution, there isn't a single \"winner.\" The analogy between evolution and search is just that: an analogy, and an imperfect one.\n\nIn evolution, there are many, many, many local maxima. To survive, you don't have to find some sort of theoretical ultimate maximum (if such a thing even exists). You just have to find one of the local maxima or a point close enough to it to work. As my evolutionary bio professor said: \"life doesn't work perfectly, it just works.\"\n\nGiven that from a mathematical point of view the solution space explored by evolution is effectively infinite, that means that there is also an effectively infinite (though smaller! infinity is weird like that...) number of local optima that could work within the space. Evolution just has to hit one of those and you've got a viable organism.\n\nWhen we humans think of search, we think of a needle in a haystack. Evolution works more in spaces where it's more like an uneven lumpy mix of needles and hay where on average there is one needle for every N pieces of hay.\n\nIn evolutionary computing you're dealing with huge (effectively infinite from our perspective) noncomputable solution spaces that have the same characteristic. You're often not looking for *the* global maximum, and in fact one of the implications of the NFL theorem is that in such spaces there is no way to say precisely where the global maximum is! You're just looking for something that works well enough to satisfy your performance constraints.\n\nIt works.\n\nhttp://www.genetic-programming.com/humancompetitive.html\n\nThe ID-creationists are, as usual, using their common trick of conceptual sleight of hand here. They talk about one thing, then they switch the context silently in mid-argument and talk about something else. The sleight of hand here is around the characteristics of the solution space. They go from talking about spaces with N solutions for every M points to talking about spaces with 1 solution for every M points. Nature isn't like that.\n", "author_flair_css_class": null}], "subreddit": "programming", "score_hidden": false, "ups": 3, "controversiality": 0, "author_flair_text": null, "link_id": "t3_5yskq", "retrieved_on": 1427425806, "body": "The \"article\" states that\n\n \"Biological evolution is often regarded as optimization, and evolutionary computation, which mimics biological evolution, also commonly takes the form of optimization.\"\n\nIn my opinion, this is a major leap in faith, not logic (where the ID people make one of many mistakes).  Evolution seems to operate on the principle of \"What ever gets you through the night\", not any traditional optimization scheme. A sort of \"Lazy Optimization\" provided by Natural Selection - there is no search for a solution, you have something to bargain with or not. In Russia, roulette spins you. ", "archived": true, "distinguished": null, "edited": false, "name": "t1_c02aju6", "parent_id": "t3_5yskq", "id": "c02aju6", "author_flair_css_class": null}